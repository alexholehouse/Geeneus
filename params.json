{"google":"UA-26309586-2","note":"Don't delete this file! It's used internally to help with page regeneration.","body":"# Geeneus\r\n#### NCBI database access made simple\r\n\r\n**NOTE: This github page hosts the development version, but not the distribution version. To get and install Geeneus, go to [the PiPi site](http://pypi.python.org/pypi/Geeneus/0.1.0) and get the installable source from there.**\r\n\r\n### Introduction\r\nGeeneus is designed as a simple to use, robust and reliable API to NCBI's various databases. Right now it provides in depth access for protein records, with limited gene record functionality. However, over time I plan to add more database types and more in depth functionality.\r\n\r\nThe motivation comes from the simple fact that when I began working with NCBI's databases I wanted an interface which allowed me to do\r\n\r\n    interface.get_protein_sequence(accession_number)\r\n\r\nand would just return the sequence associated with that accession number. This didn't exist, so I decided to create it.\r\n\r\nThe primary focus of Geeneus from day 1 has been ease of use. NCBI allows access to their records through an ENTREZ based RESTful API called [eUtils](http://www.ncbi.nlm.nih.gov/books/NBK25500/). However, this can be complicated to set up, and to people who are less used to networking or programming can pose a major barrier to access. [Biopython](http://biopython.org/) goes some way [to help with this](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc98), but still requires the user to parse XML, deal with networking, read handles, and lots of other things which are just more work.\r\n\r\nConsidering this, my goals were to;\r\n\r\n* Parse the returned XML - the user should *never* have to deal with XML unless they want to\r\n\r\n* Deal with all the networking errors - you should be able to turn your internet connection off while running and the system doesn't crash (it will probably stop getting results though)\r\n\r\n* Abstract any of the complexity to create a uniform, easy to use, Python built-in types based API. This means the various functions only return strings, lists and dictionaries.\r\n\r\n### Installation\r\nThe simplest way to is to [download the .tar.gz from the PiPi site](http://pypi.python.org/packages/source/G/Geeneus/Geeneus-0.1.0.tar.gz) and then install using\r\n\r\n    pip install Geeneus-0.1.0.tar.gz # (may need to be sudo)\r\n\r\nMore installation options can be found [here](http://pypi.python.org/pypi/Geeneus/0.1.0)\r\n\r\n### Usage\r\n\r\nFor now only protein record access usage is provided, as the gene record functionality is still in development.\r\n\r\nGeeneus as a package contains a module for each type of record you might want to parse (protein, gene etc). To set up for protein records, you do;\r\n\r\n    from geeneus import Proteome\r\n    manager = Proteome.ProteinManager(\"your.emailaddress@email.com\")\r\n\r\nAnd from there, the NCBI protein data is at your fingertips. Say we want the sequence for the *protein sprouty homolog 4 isoform 2*. This protein has the accession number NP_001120968, so we simply do\r\n\r\n    manager.get_protein_sequence(\"NP_001120968\")\r\n\r\nand we're greeted with the sequence\r\n\r\n    'meppipqsapltpnsvmvqplldsrmshsrlqhpltilpidqvktshvendyidnpslalttgpkrtrggapelaptparcdqdvthhwisfsgrpssvs\r\n     sssstssdqrlldhmapppvadqaspravriqpkvvhcqpldlkgpavppeldkhfllceacgkckckecasprtlpscwvcnqeclcsaqtlvnygtc\r\n     mclvqgifyhctneddegscadhpcscsrsnccarwsfmgalsvvlpcllcylpatgcvklaqrgydrlrrpgcrckhtnsvickaasgdakt\r\n     srpdkpf'\r\n\r\nFor the full range of functions available, try `help(manager)` or help(geneeus.Proteome) \r\n\r\n#### List of Proteome functions\r\n    get_protein_name(ProteinID)\r\n    get_protein_sequence(ProteinID)\r\n    get_raw_xml(ProteinID)\r\n    get_variants(ProteinID)\r\n    get_geneID(ProteinID)\r\n    get_protein_sequence_length(ProteinID)\r\n    get_ID_type(ProteinID)\r\n    run_translation(accession number)\r\n    batch_get_protein_sequence([List of IDs])\r\n    batch_get_protein_name([List of IDs])\r\n    batch_get_variants([List of IDs])\r\n    purge()\r\n    get_size_of_datastore()\r\n\r\n### Design Decisions\r\n\r\n#### Caching \r\nThere were a number of design decisions which were made during the projects development, and no doubt will continue to be made. The manager object builds up a local data structure, and by default caches requests it makes to the database. The upshot of this from the user's perspective is that if I run\r\n\r\n    manager.get_protein_sequence(\"NP_001120968\")\r\n    manager.get_protein_sequence(\"NP_001120968\")\r\n\r\nThe second call doesn't query the database, but just reads off the cached value. This caching behavior can be turned off on by setting `cache=False` when initializing the ProteinManager object.\r\n\r\n#### Batch queries \r\nA key design decision was how to deal with batch queries.\r\n\r\nThe eUtils recommended approach for making large (100+ IDs) queries is to initially ePost a list of those queries. The ePost operation sends this list to the ENTREZ servers, returning a `WebEnv` value and a `QueryKey` value. These two can then be used with an `eFetch` to go to the sever and get the result of the list submitted previously. The difficulty is that this list *must* be made up of UIDs (unique identifiers) which for proteins means GI numbers. If you only have an accession value (as is common) the only way to get this GI number is to query the database, and this `eSearch` operation can *not* be done in batch. Essentially, this is a chicken and egg problem - to get the GIs we need to do an `ePost` based batch query we have to run serial database queries.\r\n\r\nThis means that using `ePost`/`eFetch` would be great if you had a list of UIDs, but in practice accession numbers are a lot more common and useful, and the mapping of *n* accession values to UIDs would require *n* calls the server anyway. \r\n\r\nTo get around this, I use concatenated `eFetch` calls for batch queries, whereby a single call is submitted with a list of IDs. This is a fast and stable way to get around this problem, and, so far, as shown no issues with lists up to 100 IDs long. The potential issue is that the HTTP GET request being made here literally gets longer as we add accession values, so this represents a top limit in terms of networking protocols. However, I implemented a recursive cascading retry mechanism which halves the list and retries each half, so should a list be too long it should only result in two calls instead of one.\r\n\r\n#### Robustness\r\nA primary goal with Geeneus was to create an API which is robust to input. By this, it should be able to handle case insensitivity, convert accession values where necessary, and correctly recognize valid accession values while rejecting irrelevant ones to minimize server burden. For accession filtering, we use regular expressions to ensure the only accession values which we query could be real values (based on NCBI's [accession rules](http://www.ncbi.nlm.nih.gov/Sequin/acc.html). While PDBs don't fall into this category, we allow translation between PDBID and GI, although often a chain identifier is required as the NCBI protein database treats separate chains as separate records.\r\n\r\nAll the networking is dealt with in a highly modular fashion, and network failure tolerance is a priority.\r\n\r\n### Background and licence\r\nThis code was developed by [Alex Holehouse](http://holehouse.org) at [Washington University in Saint Louis](http://www.wustl.edu/) as part of the [Naegle lab](http://naegle.wustl.edu/people/lab_members.html). It is licensed under the the GNU General Public License (GPL-2.0). For more information see LICENCE.","name":"Geeneus","tagline":"Hyper simple protein and gene API for Entrez NCBI databases"}